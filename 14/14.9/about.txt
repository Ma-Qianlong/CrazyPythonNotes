# 多进程
    除可以进行多线程编程之外， Python 还支持使用多进程来实现并发编程。

## 1. 使用 fork 创建新进程
    Python 的 os 模块提供了 一个 fork（）方法，该方法可以 fork 出 来一个子进程。简单来说， fork()
方法的作用在于：程序会启动两个进程（ 一个是父进程， 一个是 fork 出来的子进程）来执行从 os.fork()
开始的所有代码。 fork（）方法不需要参数，它有一个返回值，该返回值表明是哪个进程在执行。
    》如果 fork（）方法返回 0，则表明是 fork 出来的子进程在执行。
    》如果 fork（）方法返回非 0，则表明是父进程在执行， 该方法返回 fork（）出来的子进程的进程ID。

        \fork_test.py （示范了使用 fork（）方法创建新进程的过程）
    在 Linux 或 Mac OS X 系统上运行上面程序（ Windows 不支持 fork（）方法，因此在 Windows 系统上运行上面程序会报错）

    在实际编程中，程序可通过 fork（）方法来创建一个子进程，然后通过判断 fork（）方法的返回值
来确定程序是否正在执行子进程，也就是把需要并发执行的任务放在 if pid == 0：的条件执行体中，
这样就可以启动多个子进程来执行并发任务。

## 2. 使用 multiprocessing.Process 创建新进程
    虽然使用 os.fork（）方法可以启动多个进程，但这种方式显然不适合 Windows，而 Python 是跨
平台的语言，所以 Python 绝不能仅仅局限于 Windows 系统，因此 Python 也提供了其他方式在
Windows 下创建新进程。
    Python 在 multiprocessing模块下提供了 Process 来创建新进程。 与 Thread 类似的是，使用 Process
创建新进程也有两种方式。
    〉 以指定函数作为 target，创建 Process 对象即可创建新进程 。
    〉 继承 Process 类，井重写它 的 run（）方法来创建进程类，程序创建 Process 子类的实例作为进程。

    Process 类也有如下类似的方法和属性。
    > run()： 重写该方法可实现进程的执行体。
    > start(): i亥方法用于启动进程。
    > join([timeout])： 该方法类似于线程的 join()方法，当前进程必须等待被 join 的进程执行完成才能向下执行。
    > name ： 该属性用于设置或访问进程的名字。
    > is_alive()：判断进程是否还活着。
    > daemon ： 该属性用于判断或世置进程的后台状态。
    > pid ： 返回进程的 PID 。
    > authkey：返回进程的授权 key 。
    > terminate()： 中断该进程。

    >>> 1. 以指定函数作为 target 创建新进程

        \first_process.py

    需要说明的是，通过 multiprocessing.Process 来创建井启动进程时，
    程序必须先判断 if __name__ == '__main__', 否则可能引发异常。

    >>> 2. 继承 Process 类创建子进程
    继承 Process 类创建子进程的步骤如下。
    a。定义继承 Process 的子类， 重写其 run（）方法准备作为进程执行体 。
    b。创建 Process 子类的实例。
    c。调用 Process 子类的实例的 start（）方法来启动进程 。

        \second_process.py

    通常，推荐使用第一种方式来创建进程，因为这种方式不仅编程简单 ，而且进程直接包装 target
函数，具有更清晰的逻辑结构 。


## 3. Context 和启动进程的方式
    根据平台的支持 ， Python 支持三种启动进程的方式 。
    》 spawn：父进程会启动一个全新的 Python 解释器进程。 在这种方式下，子进程只能继承那
       些处理 run（）方法所必需的资源。 典型的，那些不必要的文件描述器和 handle 都不会被继承。
       使用这种方式来启动进程，其效率比使用 fork 或 forkserver 方式要低得多。
    》 fork ：父进程使用 OS.fork（）来启动一个 Python 解释揣进程。 在这种方式下， 子进程会继承
       父进程的所有资源， 因此子进程基本等效于父进程。这种方式只在 UNIX 平台上有效， UNIX
       平台默认使用这种方式来启动进程。
    》 forkserver ： 如果使用这种方式来启动进程，程序将会启动一个服务器进程。 在以后的时间
       内， 当程序再次请求启动新进程时，父进程都会连接到该服务器进程， 请求由服务器进程
       来 fork 新进程。 通过这种方式启动的进程不需要从父进程继承资源。这种方式只在 UNIX
       平台上有效。

    从上面介绍可以看出，如果程序使用 UNIX 平台（包括 Linux 和 Mac OS X ）， Python 支持三种
启动进程的方式； 但如果使用 Windows 平台，则只能使用效率最低的 spawn 方式。
    multiprocessing 模块提供了 一个 set_start_ method() 函数 ， 该函数可用于设置启动进程的方式——
必须将这行设置代码放在所有与多进程有关的代码之前。

            \start_method_test.py (示范了显式设置启动进程的方式)

    还有一种设置进程启动方式的方法，就是利用 get_context（）方法来较取 Context 对象，调用该
方法时可传入 spawn 、 fork 或 forkserver 字符串。 Context 拥有和 multiprocessing 相同的 API ，因此
程序可通过 Context 来创建井启动进程。

            \Context_test.py

## 4. 使用进程池管理进程
    与线程池类似的是，如果程序需要启动多个进程，也可以使用进程池来管理进程。程序可以通
过 multiprocessing 模块的 Pool（）函数创建进程池，进程池实际上是 multiprocessing.pool.Pool 类。
    进程池具有如下常用方法。
    》》apply(func[, args[, kwds］］）：将 func 函数提交给进程池处理。其中 args 代表传给 func 的位置
        参数， kwds 代表传给func 的关键字参数。该方法会被阻塞直到 func 函数执行完成。
    》》apply_async(func[, args[, kwds[, callback[, error_callback］］］］）：这是 apply（）方法的异步版本 ，
        该方法不会被阻塞。其中 callback 指定 func 函数完成后的回调函数， error_callback 指定 func 函数出错后的回调函数。
    》》map（func， iterable[, chunksize］）：类似于 Python 的 map（）全局函数，只不过此处使用新进程
        对 iterable 的每一个元素执行 map 函数 。
    》》map_async(func, iterable[, chunksize[, callback[, eηor callback］］］）：这是 map（）方法的异步版
        本，该方法不会被阻塞。其中 callback 指定 func 函数完成后的回调函数， error_callback 指定 func 函数出错后的回调函数。
    》》imap(func, iterable[, chunksize］）：这是 map（）方法的延迟版本 。
    》》imap_unordered(func, iterable[, chunksize］）：功能类似于 imap（）方法，但该方法不能保证所
        生成的结果（包含多个元素〉与原 iterable 中的元素顺序一致。
    》》starmap(func, iterable[, chunksize］）：功能类似于 map（）方法，但该方法要求 iterable 的元素也
        是 iterable 对象，程序会将每一个元素解包之后作为 func 函数的参数。
    》》close（）：关闭进程池 。在调用该方法之后，该进程池不能再接收新任务，它会把当前进程池中的所有任务执行完成后再关闭自己。
    》》terminate（）： 立即中止进程池。
    》》join（）：等待所有进程完成。
    从上面介绍不难看出，如果程序只是想将任务提交给进程池执行，则可调用 apply（）或 apply_async（）方法；
如果程序需要使用指定函数将 iterable 转换成其他 iterable，则可使用 map() 或 imap() 方法。

            \pool_test.py(示范了使用 appIy_async() 方法启动进程)

    进程池同样实现了上下文管理协议，因此程序可以使用 with 子句来管理进程池，这样就可以避免程序主动关闭进程池。

            \pool_test2.py(示范了使用 map（）方法来启动进程)

## 5. 进程通信
    Python 为进程通信提供了两种机制。
    》 Queue：一个进程向 Queue 中放入数据 ， 另 一个进程从 Queue 中读取数据。
    》 Pipe: Pipe 代表连接两个进程的管道。 程序在调用 Pipe() 函数时会产生两个连接端 ，分别交
给通信的两个进程，接下来进程既可从该连接端读取数据，也可向该连接端写入数据。

    1. 使用 Queue 实现进程通信
    下面先看使用 Queue 来实现进程通信。 multiprocessing 模块下的 Queue 和 queue 模块下的 Queue
基本类似，它们都提供了 qsize() 、 empty() 、 full()、 put()、 put_nowait（）、 get（）、 get_nowait（）等方法。 区
别只是 multiprocessing 模块下的 Queue 为进程提供服务，而 queue 模块下的 Queue 为线程提供服务。

            \Queue_test.py(使用 Queue 来实现进程之间的通信)

    2. 使用 Pipe 实现进程通信
    使用 Pipe 实现进程通信，程序会调用 multiprocessing . Pipe（）函数来创建一个管道，该函数会返
回两个 PipeConnection 对象，代表管道的两个连接端（ 一个管道有两个连接端，分别用于连接通信的两个进程）。
    PipeConnection 对象包含如下常用方法。
    >>> send(obj）：发送一个 obj 给管道的另一端，另 一端使用 recv（）方法接收。需要说明的是，该
        obj 必须是可 picklable 的（ Python 的序列化机制），如果该对象序列化之后超过 32MB, 则很可能会引发 ValueError 异常 。
    >>> recv()：接收另 一端通过 send（）方法发送过来的数据 。
    >>> fileno()： 关于连接所使用的文件描述器。
    >>> close()：关闭连接。
    >>> poll([timeout]）： 返回连接中是否还有数据可以读取。
    >>> send_bytes(buffer[, offset[, size］］） ： 发送字节数据 。
        如果没有指定 offset、size 参数，则默认发送 buffer 字节串的全部数据：如果指定了 offset 和 size 参数，则只发送 buffer 字节串中
        从 offset 开始、长度为 size 的字节数据。通过该方法发送的数据，应该使用 recv_bytes（）或 recv_bytes_into 方法接收。
    >>> recv_bytes([maxlength］）： 接收通过 send bytes（）方法发送的数据， maxlength 指定最多接收的字节数。该方法返回接收到的字节数据。
    >>> recv_bytes_into (buffer[, offset］）：功能与 recv_bytes（）方法类似，只是该方法将接收到的数据放在 buffer 中。

            \Pipe_test.py(示范如何使用 Pipe 来实现两个进程之间的通信)
